# ğŸ¦™ Llama Chat - Interface Web pour Ollama

Une interface de chat moderne et Ã©lÃ©gante pour interagir avec les modÃ¨les Llama via Ollama. CrÃ©ez plusieurs conversations, gÃ©rez vos topics et profitez d'une expÃ©rience utilisateur fluide avec animations et notifications.

![Llama Chat Preview](https://img.shields.io/badge/React-18+-blue.svg)
![Ollama](https://img.shields.io/badge/Ollama-Compatible-green.svg)
![Tailwind CSS](https://img.shields.io/badge/Tailwind-CSS-blue.svg)

## âœ¨ FonctionnalitÃ©s

- ğŸ’¬ **Chat en temps rÃ©el** avec streaming des rÃ©ponses
- ğŸ“‚ **Gestion de topics** multiples (crÃ©er, renommer, supprimer)
- ğŸ¨ **Interface moderne** avec animations fluides
- ğŸ”” **SystÃ¨me de notifications** interactif
- ğŸ’¾ **Sauvegarde automatique** dans le localStorage
- ğŸ“± **Responsive design** pour mobile et desktop
- âš¡ **Performance optimisÃ©e** avec limitation de l'historique
- ğŸ¯ **Support Markdown** pour le formatage des rÃ©ponses

## ğŸš€ Installation

### PrÃ©requis

- **Node.js** (version 18 ou supÃ©rieure)
- **npm** ou **yarn**
- **Ollama** installÃ© et configurÃ©

### 1. Installation d'Ollama

#### Sur macOS

```bash
# TÃ©lÃ©charger et installer Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Ou via Homebrew
brew install ollama
```

#### Sur Linux

```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

#### Sur Windows

TÃ©lÃ©chargez l'installateur depuis [ollama.ai](https://ollama.ai/download)

### 2. Installation du modÃ¨le Llama

```bash
# TÃ©lÃ©charger et installer Llama 3.2 (recommandÃ©)
ollama pull llama3.2

# Alternatives disponibles :
# ollama pull llama3.1
# ollama pull llama3.2:1b    # Version plus lÃ©gÃ¨re
# ollama pull llama3.2:3b    # Version intermÃ©diaire
```

### 3. DÃ©marrage d'Ollama

```bash
# DÃ©marrer le serveur Ollama
ollama serve

# Le serveur sera disponible sur http://localhost:11434
```

### 4. Installation de l'application

```bash
# Cloner le projet
git clone <votre-repo>
cd llama3-chat

# Installer les dÃ©pendances
npm install

# DÃ©marrer l'application en mode dÃ©veloppement
npm run dev

# L'application sera disponible sur http://localhost:5173
```

## ğŸ¯ Utilisation

### Interface principale

L'application est composÃ©e de deux parties principales :

1. **Sidebar gauche** : Gestion des topics de conversation
2. **Zone de chat** : Affichage des messages et zone de saisie

### Gestion des topics

- **â• CrÃ©er un topic** : Cliquez sur "Nouveau topic" dans la sidebar
- **âœï¸ Renommer un topic** : Survolez un topic et cliquez sur l'icÃ´ne crayon
- **ğŸ—‘ï¸ Supprimer un topic** : Survolez un topic et cliquez sur l'icÃ´ne poubelle
- **ğŸ”„ Changer de topic** : Cliquez sur le nom d'un topic pour l'activer

### Envoi de messages

- **Saisie simple** : Tapez votre message et appuyez sur `EntrÃ©e`
- **Saisie multiligne** : Utilisez `Shift + EntrÃ©e` pour une nouvelle ligne
- **Envoi** : Cliquez sur le bouton "Envoyer ğŸš€" ou utilisez `EntrÃ©e`

### Raccourcis clavier

- `EntrÃ©e` : Envoyer le message
- `Shift + EntrÃ©e` : Nouvelle ligne dans le message
- `Ã‰chap` : Annuler l'Ã©dition d'un topic

## ğŸ”§ Configuration

### ModÃ¨les supportÃ©s

L'application est configurÃ©e pour utiliser `llama3.2` par dÃ©faut. Pour changer de modÃ¨le, modifiez la ligne dans `src/App.jsx` :

```javascript
model: "llama3.2", // Changez ici le nom du modÃ¨le
```

ModÃ¨les disponibles :

- `llama3.2` (recommandÃ©)
- `llama3.1`
- `llama3.2:1b` (version lÃ©gÃ¨re)
- `llama3.2:3b` (version intermÃ©diaire)

### ParamÃ¨tres de l'API

L'application communique avec Ollama via l'API REST sur `http://localhost:11434`. Si votre instance Ollama est sur un autre port ou serveur, modifiez l'URL dans `src/App.jsx` :

```javascript
const res = await fetch("http://localhost:11434/api/generate", {
  // Configuration...
});
```

### Limitation de l'historique

Par dÃ©faut, l'application limite l'historique Ã  10 messages par conversation pour optimiser les performances. Vous pouvez ajuster cette valeur dans `src/App.jsx` :

```javascript
// Limiter l'historique Ã  9 messages + le nouveau (donc max 10)
const limitedMessages =
  oldMessages.length >= 9 // Changez cette valeur
    ? oldMessages.slice(oldMessages.length - 9)
    : oldMessages;
```

## ğŸ› ï¸ DÃ©veloppement

### Structure du projet

```
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatWindow.jsx          # Zone d'affichage des messages
â”‚   â”œâ”€â”€ MessageInput.jsx        # Zone de saisie des messages
â”‚   â”œâ”€â”€ NotificationSystem.jsx  # SystÃ¨me de notifications
â”‚   â”œâ”€â”€ Sidebar.jsx            # Barre latÃ©rale des topics
â”‚   â””â”€â”€ TopicItem.jsx          # Ã‰lÃ©ment individuel de topic
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useNotifications.js    # Hook pour les notifications
â”œâ”€â”€ App.jsx                    # Composant principal
â”œâ”€â”€ index.css                 # Styles globaux et animations
â””â”€â”€ main.jsx                  # Point d'entrÃ©e React
```

### Scripts disponibles

```bash
# DÃ©veloppement
npm run dev

# Build de production
npm run build

# PrÃ©visualisation du build
npm run preview

# Linting
npm run lint
```

### Technologies utilisÃ©es

- **React 19** - Framework frontend
- **Vite** - Build tool et serveur de dÃ©veloppement
- **Tailwind CSS** - Framework CSS utilitaire
- **React Markdown** - Rendu du contenu Markdown
- **UUID** - GÃ©nÃ©ration d'identifiants uniques

## ğŸ› DÃ©pannage

### ProblÃ¨mes courants

#### Ollama n'est pas accessible

```bash
# VÃ©rifiez que Ollama est dÃ©marrÃ©
ollama serve

# VÃ©rifiez que le modÃ¨le est installÃ©
ollama list

# Testez l'API directement
curl http://localhost:11434/api/tags
```

#### Le modÃ¨le n'est pas trouvÃ©

```bash
# VÃ©rifiez les modÃ¨les disponibles
ollama list

# Installez le modÃ¨le si nÃ©cessaire
ollama pull llama3.2
```

#### Erreur CORS

Si vous rencontrez des erreurs CORS, assurez-vous qu'Ollama autorise les requÃªtes depuis votre domaine. Ollama autorise gÃ©nÃ©ralement localhost par dÃ©faut.

#### Performance lente

- Utilisez un modÃ¨le plus lÃ©ger (`llama3.2:1b`)
- Augmentez la RAM allouÃ©e Ã  Ollama
- RÃ©duisez la limite d'historique des messages

## ğŸ“ FonctionnalitÃ©s Ã  venir

- [ ] Mode sombre/clair
- [ ] Export des conversations
- [ ] Recherche dans l'historique
- [ ] Support de fichiers joints
- [ ] ParamÃ¨tres configurables de l'IA
- [ ] ThÃ¨mes personnalisables

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :

1. Fork le projet
2. CrÃ©er une branche pour votre fonctionnalitÃ©
3. Commiter vos changements
4. Pousser vers la branche
5. Ouvrir une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ”— Liens utiles

- [Documentation Ollama](https://ollama.ai/docs)
- [ModÃ¨les Llama disponibles](https://ollama.ai/library)
- [API Ollama](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [React Documentation](https://react.dev)
- [Tailwind CSS](https://tailwindcss.com)

---

**DÃ©veloppÃ© avec â¤ï¸ pour la communautÃ© IA**
